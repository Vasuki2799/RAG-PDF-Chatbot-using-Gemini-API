# ğŸ¤– RAG PDF Chatbot using Gemini API

A **Retrieval-Augmented Generation (RAG)** based chatbot that allows users to upload a PDF document and interactively ask questions strictly based on the documentâ€™s content.  
The system uses **Google Gemini models for embeddings and generation**, combined with semantic similarity search.<img width="1440" height="900" alt="Screenshot 2025-12-16 at 7 23 12â€¯PM" src="https://github.com/user-attachments/assets/d0f11ab7-e678-4c63-ab0b-84e543ce2b1f" />


---

## ğŸ“Œ Project Overview

This project demonstrates how **Large Language Models (LLMs)** can be combined with **document retrieval techniques** to build a reliable, document-aware chatbot.

The chatbot:
- Extracts text from uploaded PDFs
- Splits content into overlapping chunks
- Converts chunks into embeddings
- Retrieves the most relevant chunks using cosine similarity
- Generates answers **only from the uploaded document**

This ensures **zero hallucination** and **strict document grounding**.

---

## ğŸ§  Architecture (RAG Pipeline)

PDF Upload

â†“

Text Extraction

â†“

Chunking (with overlap)

â†“

Gemini Embeddings

â†“

Vector Similarity Search

â†“

Context Injection

â†“

Gemini Response Generation



---

## âœ¨ Features

- ğŸ“„ Upload and process PDF documents
- ğŸ” Semantic search using embeddings
- ğŸ¤– Gemini-powered question answering
- ğŸ“Š Document statistics (pages, chunks, characters)
- ğŸ’¬ Interactive Streamlit chat UI
- ğŸ§  Strict document-based answering (no external knowledge)
- ğŸ§¾ Chat history tracking
- ğŸ–¥ Terminal logging for debugging (question, chunks, answer)

---

## ğŸ›  Tech Stack

| Category | Technology |
|--------|------------|
| Frontend | Streamlit |
| LLM | Google Gemini |
| Embeddings | Gemini Embedding Model |
| Similarity Search | Cosine Similarity (scikit-learn) |
| PDF Processing | PyPDF |
| Backend | Python |
| Environment Management | python-dotenv |

---

## ğŸ“‚ Project Structure

rag-pdf-chatbot/
â”‚

â”œâ”€â”€ chatbot.py # Main Streamlit application

â”œâ”€â”€ requirements.txt # Project dependencies

â”œâ”€â”€ .gitignore # Ignored files (.env, venv, etc.)

â”œâ”€â”€ README.md # Project documentation

â””â”€â”€ .env # API key (NOT pushed to Git)



---

## ğŸ”‘ Environment Setup

1ï¸âƒ£ Clone Repository

git clone https://gitlab.com/your-username/rag-pdf-chatbot.git
cd rag-pdf-chatbot

2ï¸âƒ£ Create Virtual Environment
python -m venv .venv
source .venv/bin/activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Set Environment Variable
Create a .env file:
GEMINI_API_KEY=your_api_key_here

â–¶ï¸ Running the Application
streamlit run <file name>
The app will open in your browser.


ğŸ§ª How to Use

1. Open the application
2. Navigate to Process PDF
3. Upload a PDF document
4. Click Process Now
5. Go to Chat Interface
6. Ask questions related to the uploaded document

If a question is outside the document scope, the chatbot will respond professionally:

"Iâ€™m unable to answer this question as it falls outside the scope of the uploaded document."


ğŸ“Š Debugging Output (Terminal)

For mentor review and debugging, the following are printed in terminal:

* User question
* Retrieved document chunks
* Final generated answer

This improves traceability and transparency.


ğŸš€ Future Enhancements

* Vector database integration (FAISS / ChromaDB)
* Support for multiple documents
* Conversation memory across sessions
* File type support beyond PDF
* Cloud deployment

ğŸ‘¨â€ğŸ’» Author

Vasuki A

vasukiarul27@gmail.com

AI / ML Engineer Intern

https://www.linkedin.com/posts/vasuki27_ai-generativeai-rag-activity-7406694458991439873-4oHl?utm_source=share&utm_medium=member_desktop&rcm=ACoAAFWofHABP5vZ1q4SVksdeQ_qxpl9ilnOKXM


ğŸ“œ License

This project is created for learning and internship evaluation purposes.

---
